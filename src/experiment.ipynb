{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For running the script in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from agent.dqn import Agent\n",
    "from configurations import LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--window_size',\n",
    "                    default=100,\n",
    "                    help=\"Number of lags to include in the observation\",\n",
    "                    type=int)\n",
    "parser.add_argument('--max_position',\n",
    "                    default=10, #as used in paper\n",
    "                    help=\"Maximum number of positions that are \" +\n",
    "                         \"able to be held in a broker's inventory\",\n",
    "                    type=int)\n",
    "parser.add_argument('--fitting_file',\n",
    "                    default='XBTUSD_20200101_20200102_merge.csv.xz',\n",
    "                    #default='demo_LTC-USD_20190926.csv.xz',\n",
    "                    help=\"Data set for fitting the z-score scaler (previous day)\",\n",
    "                    type=str)\n",
    "parser.add_argument('--testing_file',\n",
    "                    default='paper_data/XBTUSD_2020-01-03.csv.xz',\n",
    "                    help=\"Data set for training the agent (current day)\",\n",
    "                    type=str)\n",
    "parser.add_argument('--symbol',\n",
    "                    default='XBTUSD',\n",
    "                    help=\"Name of currency pair or instrument\",\n",
    "                    type=str)\n",
    "parser.add_argument('--id',\n",
    "                    default='market-maker-v0',\n",
    "                    #default='trend-following-v0',\n",
    "                    help=\"Environment ID; Either 'trend-following-v0' or \"\n",
    "                         \"'market-maker-v0'\",\n",
    "                    type=str)\n",
    "parser.add_argument('--number_of_training_steps',\n",
    "                    default=1000000,\n",
    "                    help=\"Number of steps to train the agent \"\n",
    "                         \"(does not include action repeats)\",\n",
    "                    type=int)\n",
    "parser.add_argument('--gamma',\n",
    "                    default=0.99,\n",
    "                    help=\"Discount for future rewards\",\n",
    "                    type=float)\n",
    "parser.add_argument('--seed',\n",
    "                    default=1,\n",
    "                    help=\"Random number seed for data set\",\n",
    "                    type=int)\n",
    "parser.add_argument('--action_repeats',\n",
    "                    default=5,\n",
    "                    help=\"Number of steps to pass on between actions\",\n",
    "                    type=int)\n",
    "parser.add_argument('--load_weights',\n",
    "                    default=False,\n",
    "                    help=\"Load saved load_weights if TRUE, otherwise start from scratch\",\n",
    "                    type=bool)\n",
    "parser.add_argument('--visualize',\n",
    "                    default=False,\n",
    "                    help=\"Render midpoint on a screen\",\n",
    "                    type=bool)\n",
    "parser.add_argument('--training',\n",
    "                    default=True,\n",
    "                    help=\"Training or testing mode. \" +\n",
    "                         \"If TRUE, then agent starts learning, \" +\n",
    "                         \"If FALSE, then agent is tested\",\n",
    "                    type=bool)\n",
    "parser.add_argument('--reward_type',\n",
    "                    default='trade_completion',\n",
    "                    choices=['default',\n",
    "                             'default_with_fills',\n",
    "                             'realized_pnl',\n",
    "                             'differential_sharpe_ratio',\n",
    "                             'asymmetrical',\n",
    "                             'trade_completion'],\n",
    "                    help=\"\"\"\n",
    "                    reward_type: method for calculating the environment's reward:\n",
    "                    1) 'default' --> inventory count * change in midpoint price returns\n",
    "                    2) 'default_with_fills' --> inventory count * change in midpoint  \n",
    "                    price returns + closed trade PnL\n",
    "                    3) 'realized_pnl' --> change in realized pnl between time steps\n",
    "                    4) 'differential_sharpe_ratio' -->\n",
    "                    http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.7210&rep=rep1\n",
    "                    &type=pdf\n",
    "                    5) 'asymmetrical' --> extended version of *default* and enhanced \n",
    "                    with  a reward for being filled above or below midpoint, \n",
    "                    and returns only negative rewards for Unrealized PnL to discourage \n",
    "                    long-term speculation.\n",
    "                    6) 'trade_completion' --> reward is generated per trade's round trip\n",
    "                    \"\"\",\n",
    "                    type=str)\n",
    "parser.add_argument('--nn_type',\n",
    "                    default='mlp',\n",
    "                    help=\"Type of neural network to use: 'cnn' or 'mlp' \",\n",
    "                    type=str)\n",
    "parser.add_argument('--dueling_network',\n",
    "                    default=True,\n",
    "                    help=\"If TRUE, use Dueling architecture in DQN\",\n",
    "                    type=bool)\n",
    "parser.add_argument('--double_dqn',\n",
    "                    default=True,\n",
    "                    help=\"If TRUE, use double DQN for Q-value estimation\",\n",
    "                    type=bool)\n",
    "args = vars(parser.parse_args(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(kwargs):\n",
    "    LOGGER.info(f'Experiment creating agent with kwargs: {kwargs}')\n",
    "    agent = Agent(**kwargs)\n",
    "    LOGGER.info(f'Agent created. {agent}')\n",
    "    agent.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-02 11:11:07,130, 711246497.py:2] Experiment creating agent with kwargs: {'window_size': 100, 'max_position': 10, 'fitting_file': 'XBTUSD_20200101_20200102_merge.csv.xz', 'testing_file': 'paper_data/XBTUSD_2020-01-03.csv.xz', 'symbol': 'XBTUSD', 'id': 'market-maker-v0', 'number_of_training_steps': 1000000, 'gamma': 0.99, 'seed': 1, 'action_repeats': 5, 'load_weights': False, 'visualize': False, 'training': True, 'reward_type': 'trade_completion', 'nn_type': 'mlp', 'dueling_network': True, 'double_dqn': True}\n",
      "[2023-05-02 11:11:07,138, ema.py:67] EMA smoothing ENABLED: 0.99\n",
      "[2023-05-02 11:11:25,861, data_pipeline.py:49] Imported 101_20200102_merge.csv.xz from a csv in 18 seconds\n",
      "[2023-05-02 11:11:42,235, ema.py:93] Applying EMA to data...\n",
      "[2023-05-02 11:11:47,435, data_pipeline.py:49] Imported /XBTUSD_2020-01-03.csv.xz from a csv in 3 seconds\n",
      "[2023-05-02 11:11:47,802, ema.py:93] Applying EMA to data...\n",
      "[2023-05-02 11:11:48,493, data_pipeline.py:228] Adding order imbalances...\n",
      "[2023-05-02 11:11:48,555, ema.py:127] Reset EMA data.\n",
      "[2023-05-02 11:11:48,556, ema.py:93] Applying EMA to data...\n",
      "[2023-05-02 11:11:49,150, ema.py:67] EMA smoothing ENABLED: 0.99\n",
      "[2023-05-02 11:11:49,151, ema.py:67] EMA smoothing ENABLED: 0.99\n",
      "[2023-05-02 11:11:49,151, ema.py:67] EMA smoothing ENABLED: 0.99\n",
      "[2023-05-02 11:11:49,152, ema.py:67] EMA smoothing ENABLED: 0.99\n",
      "[2023-05-02 11:11:49,302, dqn.py:85] creating model for mlp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment #1 on episode #0.\n",
      "market-maker-v0 XBTUSD #1 instantiated\n",
      "observation_space: (100, 174) reward_type = TRADE_COMPLETION max_steps = 86345\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 100, 256)       44800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 100, 256)       65792     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 17)                435217    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545,809\n",
      "Trainable params: 545,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-02 11:11:49,495, dqn.py:125] None\n",
      "2023-05-02 11:11:49.674730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-02 11:11:49.675552: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-02 11:11:49.675746: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vmd102699.contaboserver.net): /proc/driver/nvidia/version does not exist\n",
      "2023-05-02 11:11:49.680906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 11:11:49.702057: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "[2023-05-02 11:11:50,330, 711246497.py:4] Agent created. Agent = DQN | env = market-maker-v0 | number_of_training_steps = 1000000\n",
      "[2023-05-02 11:11:50,332, dqn.py:142] weights_filename: /root/thesis/crypto-rl/agent/dqn_weights/dqn_market-maker-v0_mlp_weights.h5f\n",
      "[2023-05-02 11:11:50,335, dqn.py:155] checkpoint_weights_filename: /root/thesis/crypto-rl/agent/dqn_weights/dqn_market-maker-v0_weights_{step}.h5f\n",
      "[2023-05-02 11:11:50,336, dqn.py:159] log_filename: /root/thesis/crypto-rl/agent/dqn_weights/dqn_market-maker-v0_log.json\n",
      "[2023-05-02 11:11:50,338, dqn.py:165] Starting training...\n",
      "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting environment #1 on episode #0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-02 11:11:55,389, dqn.py:172] training over.\n",
      "[2023-05-02 11:11:55,392, dqn.py:173] Saving AGENT weights...\n",
      "[2023-05-02 11:11:55,511, dqn.py:175] AGENT weights saved.\n"
     ]
    }
   ],
   "source": [
    "main(kwargs=args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
