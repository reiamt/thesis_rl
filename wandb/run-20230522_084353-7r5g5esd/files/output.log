
[2023-05-22 08:43:56,555, ema.py:67] EMA smoothing ENABLED: 0.99
[2023-05-22 08:43:59,738, data_pipeline.py:49] Imported 101_20200102_merge.csv.xz from a csv in 3 seconds
[2023-05-22 08:43:59,987, ema.py:93] Applying EMA to data...
[2023-05-22 08:44:02,235, data_pipeline.py:49] Imported /XBTUSD_2020-01-03.csv.xz from a csv in 1 seconds
[2023-05-22 08:44:02,439, ema.py:93] Applying EMA to data...
[2023-05-22 08:44:02,667, data_pipeline.py:228] Adding order imbalances...
[2023-05-22 08:44:02,687, ema.py:127] Reset EMA data.
[2023-05-22 08:44:02,688, ema.py:93] Applying EMA to data...
[2023-05-22 08:44:02,881, ema.py:67] EMA smoothing ENABLED: 0.99
[2023-05-22 08:44:02,881, ema.py:67] EMA smoothing ENABLED: 0.99
[2023-05-22 08:44:02,881, ema.py:67] EMA smoothing ENABLED: 0.99
[2023-05-22 08:44:02,881, ema.py:67] EMA smoothing ENABLED: 0.99
Resetting environment #1 on episode #0.
market-maker-v0 XBTUSD #1 instantiated
observation_space: (100, 174) reward_type = TRADE_COMPLETION max_steps = 86345
Using cpu device
Resetting environment #1 on episode #0.
Logging to ./runs/7r5g5esd/DQN_1
------------------------- XBTUSD-1 TRADE_COMPLETION EPISODE RESET -------------------------
Episode Reward: -386.9881
Episode PnL: -3.39%
Trade Count: 1674
Average PnL per Trade: -0.0203%
Total # of episodes: 1
short_inventory_market_orders	=	318
short_inventory_orders_placed	=	563
short_inventory_orders_updated	=	9808
short_inventory_orders_executed	=	562
long_inventory_market_orders	=	275
long_inventory_orders_placed	=	520
long_inventory_orders_updated	=	9854
long_inventory_orders_executed	=	519
First step:	5192
===========================================================================
----------------------------------------
| logger/                  |           |
|    episode_avg_trade_pnl | -0.000203 |
|    episode_pnl           | -3.39     |
|    episode_reward        | -387      |
| rollout/                 |           |
|    ep_len_mean           | 1.46e+04  |
|    ep_rew_mean           | -387      |
|    exploration_rate      | 0.722     |
| time/                    |           |
|    episodes              | 1         |
|    fps                   | 728       |
|    time_elapsed          | 20        |
|    total_timesteps       | 14635     |
----------------------------------------
Traceback (most recent call last):
  File "agent/sb3.py", line 101, in <module>
    model.learn(
  File "/Users/tam/miniconda3/envs/thesis/lib/python3.8/site-packages/stable_baselines3/dqn/dqn.py", line 269, in learn
    return super().learn(
  File "/Users/tam/miniconda3/envs/thesis/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 311, in learn
    rollout = self.collect_rollouts(
  File "/Users/tam/miniconda3/envs/thesis/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 558, in collect_rollouts
    self._store_transition(replay_buffer, buffer_actions, new_obs, rewards, dones, infos)
  File "/Users/tam/miniconda3/envs/thesis/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 471, in _store_transition
    replay_buffer.add(
  File "/Users/tam/miniconda3/envs/thesis/lib/python3.8/site-packages/stable_baselines3/common/buffers.py", line 265, in add
    self.timeouts[self.pos] = np.array([info.get("TimeLimit.truncated", False) for info in infos])
  File "/Users/tam/miniconda3/envs/thesis/lib/python3.8/site-packages/stable_baselines3/common/buffers.py", line 265, in <listcomp>
    self.timeouts[self.pos] = np.array([info.get("TimeLimit.truncated", False) for info in infos])
KeyboardInterrupt