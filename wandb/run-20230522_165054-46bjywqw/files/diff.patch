diff --git a/__pycache__/configurations.cpython-38.pyc b/__pycache__/configurations.cpython-38.pyc
index 900e27d..8f91689 100644
Binary files a/__pycache__/configurations.cpython-38.pyc and b/__pycache__/configurations.cpython-38.pyc differ
diff --git a/agent/dqn.py b/agent/dqn.py
index 082b6aa..397277e 100644
--- a/agent/dqn.py
+++ b/agent/dqn.py
@@ -46,9 +46,6 @@ class Agent(object):
         self.env = gym.make(**kwargs)
         self.env_name = self.env.env.id
 
-        print(self.env.observation_space.shape)
-        print(self.env.action_space.n)
-
         # Create agent
         # NOTE: 'Keras-RL' uses its own frame-stacker
         self.memory_frame_stack = 1  # Number of frames to stack e.g., 1.
diff --git a/agent/sb3.py b/agent/sb3.py
index 1ab80fd..b633783 100644
--- a/agent/sb3.py
+++ b/agent/sb3.py
@@ -1,75 +1,14 @@
-from pathlib import Path
-import sys
-sys.path.append(str(Path(__file__).parent.parent.parent))
-
-from datetime import datetime as dt
+import gym
+from gym.envs.registration import register
 
 import wandb
-from wandb.integration.sb3 import WandbCallback
 
-from stable_baselines3 import DQN
 from stable_baselines3.common.monitor import Monitor
 from stable_baselines3.common.vec_env import DummyVecEnv
 from stable_baselines3.common.callbacks import BaseCallback, CallbackList, CheckpointCallback
-from stable_baselines3.common.logger import TensorBoardOutputFormat
 
-import gym
-from gym.envs.registration import register
 from gym_trading.envs.market_maker import MarketMaker
 
-# define args for env init
-env_args = {
-    "symbol": 'XBTUSD',
-    "fitting_file": 'XBTUSD_20200101_20200102_merge.csv.xz',
-    "testing_file": 'XBTUSD_2020-01-03.csv.xz',
-    "max_position": 10.,
-    "window_size": 100,
-    "seed": 1,
-    "action_repeats": 5,
-    "training": True,
-    "format_3d": False,
-    "reward_type": 'trade_completion',
-    "transaction_fee": True  
-}
-
-# register custom env as gym env
-register(id='market-maker-v0', 
-         entry_point = MarketMaker,
-         kwargs = env_args)
-
-# configs for the agent
-config = {
-    "policy_type": "MlpPolicy",
-    "total_timesteps": 500_000,
-    "env_name": "market-maker-v0",
-    "save_interval": 100_000 #steps not episodes!
-}
-
-# wandb init
-run = wandb.init(
-    project="thesis",
-    config={**config, **env_args},
-    sync_tensorboard=True,
-    save_code=True
-)
-
-wandb.run.log_code(".")
-
-# vectorize env
-def make_env(): 
-    env = gym.make(id='market-maker-v0')
-    env = Monitor(env)
-    return env
-
-env = DummyVecEnv([make_env])
-
-# define agent
-model = DQN(config['policy_type'], 
-    env, verbose=1, 
-    buffer_size=10_000,
-    tensorboard_log=f"./runs/{run.id}"
-)
-
 # class to track additional params in wandb
 class TensorboardCallback(BaseCallback):
     def __init__(self, verbose = 0):
@@ -88,30 +27,59 @@ class TensorboardCallback(BaseCallback):
         self.tb_episode_pnl = self.training_env.get_attr("tb_episode_pnl")[0]
         self.tb_episode_avg_pnl = self.training_env.get_attr("tb_episode_avg_pnl")[0]
         return True
-    
-# define callback to save agent periodically
-checkpoint_callback = CheckpointCallback(
-    save_freq=config['save_interval'],
-    save_path="saved_agents/"+str(dt.now()).split()[0]+"_"+str(run.id)+"/"
-)
-
-# concatenate all defined callbacks
-callback_list = CallbackList([TensorboardCallback(), checkpoint_callback])
-
-# train agent
-model.learn(
-    total_timesteps=config['total_timesteps'],
-    callback=callback_list,
-    log_interval=1
-)
-
-
-
-# close wandb run
-run.finish()
-
-
-
-
 
-#model.save("dqn_mm")
\ No newline at end of file
+class Agent:
+
+    def __init__(self, total_timesteps, policy_type, save_interval, save_code, log_code, **env_args):
+        self.total_timesteps = total_timesteps
+        self.policy_type = policy_type
+        self.save_interval = save_interval
+        self.save_code = save_code
+
+        # register and create vectorized env
+        register(id='market-maker-v0', entry_point = MarketMaker, kwargs = env_args)
+        self.env = DummyVecEnv([self._make_env])
+
+        # init wandb
+        self.log_code = log_code
+        self.wandb_config = {
+            "project": "thesis",
+            "sync_tensorboard": True,
+            "save_code": self.save_code,
+            "config": {
+                "total_timesteps": self.total_timesteps,
+                "policy_type": self.policy_type,
+                "save_interval": self.save_interval,
+                **env_args
+            }
+        }
+        '''
+        self.run = wandb.init(
+            project="thesis",
+            config={
+                "total_timesteps": self.total_timesteps,
+                "policy_type": self.policy_type,
+                "save_interval": self.save_interval,
+                **env_args
+            },
+            sync_tensorboard=True,
+            save_code=self.save_code
+        )
+        if log_code:
+            wandb.run.log_code(".")
+        '''
+        
+
+    def __str__(self):
+        pass
+
+    def _make_env(self):
+        env = gym.make(id='market-maker-v0')
+        env = Monitor(env)
+        return env
+
+
+    def start(self):
+        run = wandb.init(**self.wandb_config)
+
+        pass
\ No newline at end of file
diff --git a/dqn_mm.zip b/dqn_mm.zip
deleted file mode 100644
index 2a2f36c..0000000
Binary files a/dqn_mm.zip and /dev/null differ
diff --git a/experiment.py b/experiment.py
index d021811..db289d2 100755
--- a/experiment.py
+++ b/experiment.py
@@ -19,11 +19,7 @@ parser.add_argument('--fitting_file',
                     help="Data set for fitting the z-score scaler (previous day)",
                     type=str)
 parser.add_argument('--testing_file',
-<<<<<<< HEAD
-                    default='XBTUSD_2020-01-03.csv.xz',
-=======
                     default='XBTUSD_2020-01-03_red.csv.xz',
->>>>>>> main
                     help="Data set for training the agent (current day)",
                     type=str)
 parser.add_argument('--symbol',
diff --git a/indicators/__pycache__/ema.cpython-38.pyc b/indicators/__pycache__/ema.cpython-38.pyc
index e39264f..0233db8 100644
Binary files a/indicators/__pycache__/ema.cpython-38.pyc and b/indicators/__pycache__/ema.cpython-38.pyc differ
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 6580302..ea379d3 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20230522_094123-hffyh74v/logs/debug-internal.log
\ No newline at end of file
+run-20230522_165054-46bjywqw/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index 2189bf6..f406abb 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20230522_094123-hffyh74v/logs/debug.log
\ No newline at end of file
+run-20230522_165054-46bjywqw/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index 11506dc..8baa9ae 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20230522_094123-hffyh74v
\ No newline at end of file
+run-20230522_165054-46bjywqw
\ No newline at end of file
